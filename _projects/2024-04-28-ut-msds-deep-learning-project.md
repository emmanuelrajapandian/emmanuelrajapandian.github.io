---
title: "Autonomous RL-DL Agent for Realtime multiplayer SuperTuxKart Ice-Hockey"
collection: projects
urlslug: "ut-msds-deep-learning-project"
type: "Academic"
permalink: /projects/2024-04-28-ut-msds-deep-learning-project
contributors: "Emmanuel Rajapandian, Jean Del Rosario Pegeuro"
contribution: "Generated training dataset of over 300 episodes of agent gameplay for imitation learning, coded and trained multi-layer perceptron model using imitation learning combining Behavioural modelling and DAgger, wrote major sections of project report."
date: 2024-04-28
teaserurl: 'tournament-run.gif'
reporturl: 'https://github.com/emmanuelrajapandian/emmanuelrajapandian.github.io/blob/master/files/Project%20Report.pdf'
excerpt: 'We design an automated agent to play SuperTuxKart Ice Hockey which is a game featuring a vast state space, a diverse action space, and sparse rewards, presenting a highly formidable challenge. The objective of the agent is to maximize goal scoring in any difficulty and achieve victory in the match if possible. Our approach involves using imitation learning, combining both Behavioural Cloning and DAgger, to mimic other agents and learn the optimal strategy for playing the game. We employ REINFORCE on top of our best imitation agent to adjust the variables of the agent&apos;s policy in an approach that increases the likelihood of actions that result in higher rewards 1.e., an effective goal-scoring strategy. Our system is designed to exploit potential simplifications in this complex environment, with the ultimate aim of creating proficient players. We train a neural net model, inspired by the principles of imitation learning, to support a controller network to play ice hockey. Our system is state-based, focusing on the state of the game rather than the visual input from the player&apos;s field of view.'
---

Emmanuel Rajapandian, Jean Del Rosario Pegeuro

<p align="justify"> 
**Description:**
We design an automated agent to play SuperTuxKart Ice Hockey which is a game featuring a vast state space, a diverse action space, and sparse rewards, presenting a highly formidable challenge. The objective of the agent is to maximize goal scoring in any difficulty and achieve victory in the match if possible. Our approach involves using imitation learning, combining both Behavioural Cloning and DAgger, to mimic other agents and learn the optimal strategy for playing the game. We employ REINFORCE on top of our best imitation agent to adjust the variables of the agent's policy in an approach that increases the likelihood of actions that result in higher rewards 1.e., an effective goal-scoring strategy. Our system is designed to exploit potential simplifications in this complex environment, with the ultimate aim of creating proficient players. We train a neural net model, inspired by the principles of imitation learning, to support a controller network to play ice hockey. Our system is state-based, focusing on the state of the game rather than the visual input from the player's field of view. </p>

**My contribution:**
<p align="justify"> 
Generated training dataset of over 300 episodes of agent gameplay for imitation learning, coded and trained multi-layer perceptron model using imitation learning combining Behavioural modelling and DAgger, wrote major sections of project report.</p>

**Report:** [[Technical report](https://github.com/emmanuelrajapandian/emmanuelrajapandian.github.io/blob/master/files/Project%20Report.pdf)]

**Code:** Owing to UT Austin Honor Code, the model files will not be made public.
